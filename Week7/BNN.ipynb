{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code is importing several libraries and modules in a Python script. Let's go through each import statement:\n",
    "\n",
    "1. `import numpy as np`: This imports the NumPy library and assigns it the alias `np`. NumPy is a powerful library for numerical computing in Python, providing support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays.\n",
    "\n",
    "2. `import tensorflow as tf`: This imports the TensorFlow library and assigns it the alias `tf`. TensorFlow is an open-source machine learning framework that allows you to build and train various types of machine learning models, including neural networks. It provides a flexible and efficient way to define, optimize, and execute computational graphs.\n",
    "\n",
    "3. `import tensorflow_probability as tfp`: This imports the TensorFlow Probability library and assigns it the alias `tfp`. TensorFlow Probability is an extension of TensorFlow that provides tools for probabilistic modeling and statistical inference. It allows you to define and train models that incorporate uncertainty and make probabilistic predictions.\n",
    "\n",
    "4. `from tensorflow.keras import layers`: This imports the `layers` module from the `tensorflow.keras` package. Keras is a high-level neural networks API that is integrated into TensorFlow. The `layers` module provides a collection of pre-built layers that can be used to construct neural networks.\n",
    "\n",
    "5. `from tensorflow.keras.models import Model`: This imports the `Model` class from the `tensorflow.keras.models` module. The `Model` class is a fundamental component of Keras and represents a neural network model. It allows you to define the architecture of a model by assembling layers and provides methods for training, evaluation, and prediction.\n",
    "\n",
    "By importing these libraries and modules, the script gains access to a wide range of functions, classes, and tools for building and training neural networks and performing numerical computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSN\n",
      "0.401606426\n",
      "0.903614458\n",
      "1.40562249\n",
      "1.907630522\n",
      "2.409638554\n",
      "2.911646586\n",
      "3.413654618\n",
      "3.915662651\n",
      "4.417670683\n",
      "4.919678715\n",
      "5.421686747\n",
      "5.923694779\n",
      "6.425702811\n",
      "6.927710843\n",
      "7.429718876\n",
      "7.931726908\n",
      "8.43373494\n",
      "8.935742972\n",
      "9.437751004\n",
      "9.939759036\n",
      "10.44176707\n",
      "10.9437751\n",
      "11.44578313\n",
      "11.94779116\n",
      "12.4497992\n",
      "12.95180723\n",
      "13.45381526\n",
      "13.95582329\n",
      "14.45783133\n",
      "14.95983936\n",
      "15.46184739\n",
      "15.96385542\n",
      "16.46586345\n",
      "16.96787149\n",
      "17.46987952\n",
      "17.97188755\n",
      "18.47389558\n",
      "18.97590361\n",
      "19.47791165\n",
      "19.97991968\n",
      "20.48192771\n",
      "20.98393574\n",
      "21.48594378\n",
      "21.98795181\n",
      "22.48995984\n",
      "22.99196787\n",
      "23.4939759\n",
      "23.99598394\n",
      "24.49799197\n",
      "25\n",
      "Earthquake Magnitude\n",
      "Hypocenter Depth (km)\n",
      "Joyner-Boore Dist. (km)\n",
      "Vs30 (m/s) selected for analysis\n",
      "PGA (g)\n",
      "PGV (cm/sec)\n",
      "T0.010S\n",
      "T0.020S\n",
      "T0.022S\n",
      "T0.025S\n",
      "T0.029S\n",
      "T0.030S\n",
      "T0.032S\n",
      "T0.035S\n",
      "T0.036S\n",
      "T0.040S\n",
      "T0.042S\n",
      "T0.044S\n",
      "T0.045S\n",
      "T0.046S\n",
      "T0.048S\n",
      "T0.050S\n",
      "T0.055S\n",
      "T0.060S\n",
      "T0.065S\n",
      "T0.067S\n",
      "T0.070S\n",
      "T0.075S\n",
      "T0.080S\n",
      "T0.085S\n",
      "T0.090S\n",
      "T0.095S\n",
      "T0.100S\n",
      "T0.110S\n",
      "T0.120S\n",
      "T0.130S\n",
      "T0.133S\n",
      "T0.140S\n",
      "T0.150S\n",
      "T0.160S\n",
      "T0.170S\n",
      "T0.180S\n",
      "T0.190S\n",
      "T0.200S\n",
      "T0.220S\n",
      "T0.240S\n",
      "T0.250S\n",
      "T0.260S\n",
      "T0.280S\n",
      "T0.290S\n",
      "T0.300S\n",
      "T0.320S\n",
      "T0.340S\n",
      "T0.350S\n",
      "T0.360S\n",
      "T0.380S\n",
      "T0.400S\n",
      "T0.420S\n",
      "T0.440S\n",
      "T0.450S\n",
      "T0.460S\n",
      "T0.480S\n",
      "T0.500S\n",
      "T0.550S\n",
      "T0.600S\n",
      "T0.650S\n",
      "T0.667S\n",
      "T0.700S\n",
      "T0.750S\n",
      "T0.800S\n",
      "T0.850S\n",
      "T0.900S\n",
      "T0.950S\n",
      "T1.000S\n",
      "T1.100S\n",
      "T1.200S\n",
      "T1.300S\n",
      "T1.400S\n",
      "T1.500S\n",
      "T1.600S\n",
      "T1.700S\n",
      "T1.800S\n",
      "T1.900S\n",
      "T2.000S\n",
      "T2.200S\n",
      "T2.400S\n",
      "T2.500S\n",
      "T2.600S\n",
      "T2.800S\n",
      "T3.000S\n",
      "T3.200S\n",
      "T3.400S\n",
      "T3.500S\n",
      "T3.600S\n",
      "T3.800S\n",
      "T4.000S\n",
      "T4.200S\n",
      "T4.400S\n",
      "T4.600S\n",
      "T4.800S\n",
      "T5.000S\n",
      "T5.500S\n",
      "T6.000S\n",
      "T6.500S\n",
      "T7.000S\n",
      "T7.500S\n",
      "T8.000S\n",
      "T8.500S\n",
      "T9.000S\n",
      "T9.500S\n",
      "T10.000S\n",
      "T11.000S\n",
      "T12.000S\n",
      "T13.000S\n",
      "T14.000S\n",
      "T15.000S\n",
      "T20.000S\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "import pandas as pd\n",
    "file_name = \"req_time_x\"\n",
    "file_path = \"C:/Users/adity/OneDrive/Desktop/Sixth Semester/CE6018 Seismic Data Analytics/Program/Week7/ReqResampleData/req_resampled_freq_x.csv\"\n",
    "reqData = pd.read_csv(file_path)\n",
    "\n",
    "reqData\n",
    "for i in reqData.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.047520\n",
       "1        0.040997\n",
       "2        0.018463\n",
       "3        0.122490\n",
       "4        0.234620\n",
       "           ...   \n",
       "14080    0.002038\n",
       "14081    0.000652\n",
       "14082    0.000432\n",
       "14083    0.000371\n",
       "14084    0.000007\n",
       "Name: T0.010S, Length: 14085, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input features and output columns\n",
    "X_val = [\"Earthquake Magnitude\",\n",
    "         \"Hypocenter Depth (km)\", \"Joyner-Boore Dist. (km)\", \"Vs30 (m/s) selected for analysis\"]\n",
    "Xreq = reqData[X_val]\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "\n",
    "# Y_val=[\"0.401606426\", \"0.903614458\", \"1.40562249\", \"1.907630522\", \"2.409638554\", \"2.911646586\", \"3.413654618\", \"3.915662651\", \"4.417670683\", \"4.919678715\", \"5.421686747\", \"5.923694779\", \"6.425702811\", \"6.927710843\", \"7.429718876\", \"7.931726908\", \"8.43373494\", \"8.935742972\", \"9.437751004\", \"9.939759036\", \"10.44176707\", \"10.9437751\", \"11.44578313\", \"11.94779116\", \"12.4497992\", \"12.95180723\", \"13.45381526\", \"13.95582329\", \"14.45783133\", \"14.95983936\", \"15.46184739\", \"15.96385542\", \"16.46586345\", \"16.96787149\", \"17.46987952\", \"17.97188755\", \"18.47389558\", \"18.97590361\", \"19.47791165\", \"19.97991968\", \"20.48192771\", \"20.98393574\", \"21.48594378\", \"21.98795181\", \"22.48995984\", \"22.99196787\", \"23.4939759\", \"23.99598394\", \"24.49799197\", \"25\"\n",
    "#                ]\n",
    "Y_val=\"T0.010S\"\n",
    "Yreq = reqData[Y_val]\n",
    "Yreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet is splitting data into train and test sets. Let's break it down step by step:\n",
    "\n",
    "1. The variable `split` is calculated as 80% of the length of the data `X`. This will determine the index at which the data will be split.\n",
    "2. The data `X` is split into two parts: `X_train` and `X_test`. The first part, `X_train`, contains the data from index 0 to `split-1`, while the second part, `X_test`, contains the data from index `split` to the end of the data.\n",
    "3. Similarly, the target variable `y` is split into `y_train` and `y_test` using the same indices as `X_train` and `X_test`.\n",
    "\n",
    "In summary, this code is performing a simple train-test split, where 80% of the data is used for training and 20% is used for testing. The variables `X_train`, `X_test`, `y_train`, and `y_test` will hold the respective portions of the data for further processing or analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# Normalizing the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scalerX = MinMaxScaler()\n",
    "scalerY = MinMaxScaler()\n",
    "X_normalized = scalerX.fit_transform(Xreq)\n",
    "Y_normalized = scalerY.fit_transform(Yreq.values.reshape(-1, 1))\n",
    "# Y_normalized = scalerY.fit_transform(Yreq)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_normalized, Y_normalized, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function called `build_model` that constructs a neural network model using the Keras library. The function takes an `input_shape` parameter, which specifies the shape of the input data.\n",
    "\n",
    "Here's a step-by-step breakdown of the code:\n",
    "\n",
    "1. The function starts by creating an input layer using `tf.keras.Input`. The `shape` parameter is set to `(input_shape,)`, which means the input data is expected to have `input_shape` dimensions.\n",
    "\n",
    "2. The input layer is then passed through a dense layer with 64 units and a ReLU activation function. The `layers.Dense` function is used to create this layer. The output of this layer is assigned to the variable `x`.\n",
    "\n",
    "3. A dropout layer is added after the first dense layer. Dropout is a regularization technique that randomly sets a fraction of input units to 0 during training, which helps prevent overfitting. The `layers.Dropout` function is used to create this layer. The dropout rate is set to 0.5, meaning 50% of the input units will be randomly set to 0 during training.\n",
    "\n",
    "4. Another dense layer with 64 units and a ReLU activation function is added after the dropout layer. The output of this layer is assigned to the variable `x`.\n",
    "\n",
    "5. Another dropout layer is added after the second dense layer.\n",
    "\n",
    "6. Finally, a dense layer with 1 unit and a linear activation function is added. This layer serves as the output layer for regression tasks. The output of this layer is assigned to the variable `outputs`.\n",
    "\n",
    "7. The `Model` function is used to create the final model. It takes the input layer (`inputs`) and the output layer (`outputs`) as arguments. The resulting model is assigned to the variable `model`.\n",
    "\n",
    "8. The function returns the created model.\n",
    "\n",
    "This code defines a simple neural network model with two dense layers and two dropout layers. It is commonly used for regression tasks, where the goal is to predict a continuous value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Bayesian neural network architecture\n",
    "def build_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=(input_shape,))\n",
    "    x = layers.Dense(64, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # outputs = layers.Dense(50, activation='linear')(x)  # 1 unit for regression\n",
    "    outputs = layers.Dense(1, activation='linear')(x)  # 1 unit for regression\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code defines a custom loss function called `negative_log_likelihood` for variational inference in regression. Let's break it down step by step:\n",
    "\n",
    "1. The function takes two parameters: `y_true` and `y_pred`. These parameters represent the true values (`y_true`) and the predicted values (`y_pred`) for the regression problem.\n",
    "\n",
    "2. Inside the function, a probability distribution object is created using the `tfp.distributions.Normal` class from the TensorFlow Probability library. This distribution represents a normal distribution with a mean equal to `y_pred` and a constant variance of 1.\n",
    "\n",
    "3. The negative log-likelihood is then calculated using the `log_prob` method of the distribution object. The negative log-likelihood measures the discrepancy between the true values and the predicted values, with a lower value indicating a better fit.\n",
    "\n",
    "4. Finally, the negative log-likelihood is averaged over all the samples using the `reduce_mean` function from TensorFlow. This provides a single scalar value that represents the overall performance of the model.\n",
    "\n",
    "The purpose of this custom loss function is to guide the training process of a regression model using variational inference. By minimizing the negative log-likelihood, the model aims to improve its predictions and fit the true values more accurately.\n",
    "\n",
    "It's worth noting that the assumption of a constant variance of 1 may not always be appropriate for all regression problems. Depending on the specific requirements of your problem, you may need to modify this code to use a different variance or distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function for variational inference in regression\n",
    "def negative_log_likelihood(y_true, y_pred):\n",
    "    dist = tfp.distributions.Normal(\n",
    "        loc=y_pred, scale=1)  # Assume constant variance\n",
    "    return -tf.reduce_mean(dist.log_prob(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function `prior` that creates a prior distribution for the weights of a Bayesian neural network. Here's a breakdown:\n",
    "\n",
    "1. `def prior(kernel_size, bias_size, dtype=None):` This line defines the function `prior` which takes three arguments: `kernel_size`, `bias_size`, and `dtype`. `kernel_size` and `bias_size` are the sizes of the weights and biases of a layer in the neural network, respectively. `dtype` is the data type of the elements of the created TensorFlow tensor.\n",
    "\n",
    "2. `n = kernel_size + bias_size` This line calculates the total size of the weights and biases for a layer in the neural network.\n",
    "\n",
    "3. `return lambda t: tfd.Normal(loc=tf.zeros(n, dtype=dtype), scale=1.0)` This line returns a lambda function that, when called, returns a Normal distribution object. This Normal distribution has a mean (`loc`) of 0 (a tensor of zeros of size `n` is created using `tf.zeros(n, dtype=dtype)`) and a standard deviation (`scale`) of 1. This Normal distribution represents the prior belief about the weights and biases before seeing any data. In this case, the prior belief is that the weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define prior for weight distributions\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return lambda t: tfd.Normal(loc=tf.zeros(n, dtype=dtype), scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code is a function called `posterior` that defines the posterior distribution for weight distributions in a neural network. Let's break down the code step by step:\n",
    "\n",
    "1. The function `posterior` takes three arguments: `kernel_size`, `bias_size`, and `dtype`. These arguments specify the sizes of the kernel (weight) and bias tensors, as well as the data type of the variables.\n",
    "\n",
    "2. Inside the function, a variable layer is created using `tfp.layers.VariableLayer`. This layer is responsible for creating trainable variables for the weight distributions. The `params_size` method of `MultivariateNormalTriL` is used to determine the number of parameters needed for the weight distributions based on the sum of `kernel_size` and `bias_size`. The `dtype` argument is passed to specify the data type of the variables.\n",
    "\n",
    "3. Next, a `MultivariateNormalTriL` layer is created using `tfp.layers.MultivariateNormalTriL`. This layer represents a multivariate normal distribution with a lower triangular covariance matrix. The number of dimensions for the distribution is set to `n`, which is the sum of `kernel_size` and `bias_size`. The `activity_regularizer` argument is set to `tfp.layers.KLDivergenceRegularizer`, which calculates the Kullback-Leibler (KL) divergence between the posterior distribution and a prior distribution. The `weight` argument is set to 1, indicating that the KL divergence regularization should be applied with a weight of 1.\n",
    "\n",
    "4. Finally, the two layers are combined into a `tf.keras.Sequential` model, which represents a sequence of layers. The model is returned as the output of the `posterior` function.\n",
    "\n",
    "In summary, the `posterior` function creates a model that represents the posterior distribution for weight distributions in a neural network. This distribution is used to regularize the weights during training by applying the Kullback-Leibler divergence regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define posterior for weight distributions\n",
    "def posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(\n",
    "            tfp.layers.MultivariateNormalTriL.params_size(n), dtype=dtype),\n",
    "        tfp.layers.MultivariateNormalTriL(\n",
    "            n, activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,545</span> (17.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,545\u001b[0m (17.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create Bayesian neural network\n",
    "model = build_model(X_train.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert model to Bayesian by using Variational Layers\n",
    "tfd = tfp.distributions\n",
    "batch_size = 32\n",
    "\n",
    "model.compile(loss=negative_log_likelihood,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.9443 - mae: 0.1524 - val_loss: 0.9202 - val_mae: 0.0232\n",
      "Epoch 2/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9206 - mae: 0.0334 - val_loss: 0.9202 - val_mae: 0.0259\n",
      "Epoch 3/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0268 - val_loss: 0.9202 - val_mae: 0.0269\n",
      "Epoch 4/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0273 - val_loss: 0.9201 - val_mae: 0.0268\n",
      "Epoch 5/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9203 - mae: 0.0273 - val_loss: 0.9201 - val_mae: 0.0274\n",
      "Epoch 6/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9201 - mae: 0.0263 - val_loss: 0.9201 - val_mae: 0.0278\n",
      "Epoch 7/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9202 - mae: 0.0274 - val_loss: 0.9201 - val_mae: 0.0263\n",
      "Epoch 8/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0265 - val_loss: 0.9201 - val_mae: 0.0265\n",
      "Epoch 9/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0257 - val_loss: 0.9201 - val_mae: 0.0273\n",
      "Epoch 10/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0264 - val_loss: 0.9201 - val_mae: 0.0247\n",
      "Epoch 11/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0263 - val_loss: 0.9201 - val_mae: 0.0271\n",
      "Epoch 12/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0251 - val_loss: 0.9200 - val_mae: 0.0238\n",
      "Epoch 13/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0254 - val_loss: 0.9200 - val_mae: 0.0235\n",
      "Epoch 14/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0256 - val_loss: 0.9200 - val_mae: 0.0208\n",
      "Epoch 15/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9200 - val_mae: 0.0245\n",
      "Epoch 16/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0254 - val_loss: 0.9200 - val_mae: 0.0208\n",
      "Epoch 17/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0246 - val_loss: 0.9200 - val_mae: 0.0241\n",
      "Epoch 18/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0249 - val_loss: 0.9200 - val_mae: 0.0230\n",
      "Epoch 19/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0255 - val_loss: 0.9200 - val_mae: 0.0249\n",
      "Epoch 20/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0246 - val_loss: 0.9201 - val_mae: 0.0335\n",
      "Epoch 21/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0256 - val_loss: 0.9200 - val_mae: 0.0258\n",
      "Epoch 22/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0256 - val_loss: 0.9200 - val_mae: 0.0219\n",
      "Epoch 23/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0250 - val_loss: 0.9199 - val_mae: 0.0202\n",
      "Epoch 24/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0241 - val_loss: 0.9200 - val_mae: 0.0263\n",
      "Epoch 25/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0236\n",
      "Epoch 26/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0264 - val_loss: 0.9200 - val_mae: 0.0206\n",
      "Epoch 27/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0248 - val_loss: 0.9199 - val_mae: 0.0220\n",
      "Epoch 28/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0254 - val_loss: 0.9200 - val_mae: 0.0219\n",
      "Epoch 29/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0242 - val_loss: 0.9200 - val_mae: 0.0231\n",
      "Epoch 30/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0232\n",
      "Epoch 31/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0253 - val_loss: 0.9200 - val_mae: 0.0204\n",
      "Epoch 32/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9202 - mae: 0.0257 - val_loss: 0.9199 - val_mae: 0.0223\n",
      "Epoch 33/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0239\n",
      "Epoch 34/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 35/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0222\n",
      "Epoch 36/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0258 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 37/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0230\n",
      "Epoch 38/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0215\n",
      "Epoch 39/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9199 - val_mae: 0.0211\n",
      "Epoch 40/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0252 - val_loss: 0.9199 - val_mae: 0.0211\n",
      "Epoch 41/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 42/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0225\n",
      "Epoch 43/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 44/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0247 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 45/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0249 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 46/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0258\n",
      "Epoch 47/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0251 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 48/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0228\n",
      "Epoch 49/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0191\n",
      "Epoch 50/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0254 - val_loss: 0.9199 - val_mae: 0.0223\n",
      "Epoch 51/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0224\n",
      "Epoch 52/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0255 - val_loss: 0.9200 - val_mae: 0.0216\n",
      "Epoch 53/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0244 - val_loss: 0.9200 - val_mae: 0.0201\n",
      "Epoch 54/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0240 - val_loss: 0.9200 - val_mae: 0.0211\n",
      "Epoch 55/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0249 - val_loss: 0.9200 - val_mae: 0.0215\n",
      "Epoch 56/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0249 - val_loss: 0.9199 - val_mae: 0.0226\n",
      "Epoch 57/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0244 - val_loss: 0.9200 - val_mae: 0.0218\n",
      "Epoch 58/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0247 - val_loss: 0.9200 - val_mae: 0.0221\n",
      "Epoch 59/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0247 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 60/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 61/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0247 - val_loss: 0.9199 - val_mae: 0.0218\n",
      "Epoch 62/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0211\n",
      "Epoch 63/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0232\n",
      "Epoch 64/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0233 - val_loss: 0.9200 - val_mae: 0.0214\n",
      "Epoch 65/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0221\n",
      "Epoch 66/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0244\n",
      "Epoch 67/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0256 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 68/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0195\n",
      "Epoch 69/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9200 - val_mae: 0.0201\n",
      "Epoch 70/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0249 - val_loss: 0.9200 - val_mae: 0.0237\n",
      "Epoch 71/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0202\n",
      "Epoch 72/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 73/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 74/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0236\n",
      "Epoch 75/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0235\n",
      "Epoch 76/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0250 - val_loss: 0.9199 - val_mae: 0.0206\n",
      "Epoch 77/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0206\n",
      "Epoch 78/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0212\n",
      "Epoch 79/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9200 - val_mae: 0.0204\n",
      "Epoch 80/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 81/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 82/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0220\n",
      "Epoch 83/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0223\n",
      "Epoch 84/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0230\n",
      "Epoch 85/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0250 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 86/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9204 - mae: 0.0260 - val_loss: 0.9199 - val_mae: 0.0195\n",
      "Epoch 87/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0227\n",
      "Epoch 88/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0235\n",
      "Epoch 89/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 90/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9200 - val_mae: 0.0236\n",
      "Epoch 91/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 92/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0220\n",
      "Epoch 93/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0259 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 94/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0221\n",
      "Epoch 95/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0212\n",
      "Epoch 96/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0225\n",
      "Epoch 97/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0256 - val_loss: 0.9200 - val_mae: 0.0213\n",
      "Epoch 98/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0246\n",
      "Epoch 99/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 100/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0222\n",
      "Epoch 101/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0226\n",
      "Epoch 102/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9200 - val_mae: 0.0212\n",
      "Epoch 103/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0218\n",
      "Epoch 104/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0229\n",
      "Epoch 105/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0197\n",
      "Epoch 106/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0201\n",
      "Epoch 107/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0232\n",
      "Epoch 108/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0236\n",
      "Epoch 109/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0226\n",
      "Epoch 110/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0211\n",
      "Epoch 111/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0222\n",
      "Epoch 112/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0200\n",
      "Epoch 113/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 114/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0223\n",
      "Epoch 115/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9200 - val_mae: 0.0231\n",
      "Epoch 116/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0248 - val_loss: 0.9199 - val_mae: 0.0200\n",
      "Epoch 117/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0213\n",
      "Epoch 118/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0223\n",
      "Epoch 119/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0213\n",
      "Epoch 120/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 121/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0199\n",
      "Epoch 122/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0234\n",
      "Epoch 123/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0202\n",
      "Epoch 124/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0251 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 125/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9200 - val_mae: 0.0203\n",
      "Epoch 126/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0222\n",
      "Epoch 127/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0218\n",
      "Epoch 128/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0253 - val_loss: 0.9199 - val_mae: 0.0199\n",
      "Epoch 129/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0225 - val_loss: 0.9199 - val_mae: 0.0211\n",
      "Epoch 130/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 131/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 132/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9200 - val_mae: 0.0234\n",
      "Epoch 133/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 134/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0223\n",
      "Epoch 135/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 136/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0250\n",
      "Epoch 137/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0242\n",
      "Epoch 138/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0253 - val_loss: 0.9199 - val_mae: 0.0230\n",
      "Epoch 139/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9200 - val_mae: 0.0201\n",
      "Epoch 140/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0228\n",
      "Epoch 141/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 142/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9199 - val_mae: 0.0229\n",
      "Epoch 143/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0215\n",
      "Epoch 144/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0229\n",
      "Epoch 145/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0198\n",
      "Epoch 146/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0227\n",
      "Epoch 147/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0202\n",
      "Epoch 148/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9199 - val_mae: 0.0221\n",
      "Epoch 149/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 150/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 151/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 152/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0254 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 153/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0194\n",
      "Epoch 154/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0212\n",
      "Epoch 155/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 156/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0225\n",
      "Epoch 157/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0218\n",
      "Epoch 158/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 159/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0192\n",
      "Epoch 160/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 161/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 162/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 163/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 164/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0244 - val_loss: 0.9199 - val_mae: 0.0195\n",
      "Epoch 165/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0236\n",
      "Epoch 166/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0248 - val_loss: 0.9199 - val_mae: 0.0193\n",
      "Epoch 167/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0227 - val_loss: 0.9199 - val_mae: 0.0221\n",
      "Epoch 168/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 169/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0234\n",
      "Epoch 170/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 171/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0248 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 172/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0204\n",
      "Epoch 173/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0212\n",
      "Epoch 174/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 175/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0227\n",
      "Epoch 176/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0196\n",
      "Epoch 177/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 178/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 179/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0248 - val_loss: 0.9199 - val_mae: 0.0211\n",
      "Epoch 180/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0212\n",
      "Epoch 181/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 182/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0223 - val_loss: 0.9198 - val_mae: 0.0196\n",
      "Epoch 183/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0206\n",
      "Epoch 184/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 185/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 186/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 187/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 188/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0233\n",
      "Epoch 189/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 190/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0215\n",
      "Epoch 191/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0194\n",
      "Epoch 192/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 193/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 194/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0200\n",
      "Epoch 195/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0235\n",
      "Epoch 196/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 197/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9200 - val_mae: 0.0202\n",
      "Epoch 198/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0227 - val_loss: 0.9198 - val_mae: 0.0216\n",
      "Epoch 199/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 200/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0230\n",
      "Epoch 201/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 202/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0193\n",
      "Epoch 203/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0220\n",
      "Epoch 204/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0241\n",
      "Epoch 205/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0238\n",
      "Epoch 206/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 207/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 208/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 209/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 210/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 211/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0195\n",
      "Epoch 212/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9198 - mae: 0.0219 - val_loss: 0.9198 - val_mae: 0.0225\n",
      "Epoch 213/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0191\n",
      "Epoch 214/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 215/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0204\n",
      "Epoch 216/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0202\n",
      "Epoch 217/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0225\n",
      "Epoch 218/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 219/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9199 - val_mae: 0.0197\n",
      "Epoch 220/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0206\n",
      "Epoch 221/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 222/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0221\n",
      "Epoch 223/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0250\n",
      "Epoch 224/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0254 - val_loss: 0.9199 - val_mae: 0.0216\n",
      "Epoch 225/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 226/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 227/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 228/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 229/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 230/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 231/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0246 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 232/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0198\n",
      "Epoch 233/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9199 - val_mae: 0.0199\n",
      "Epoch 234/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 235/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0220\n",
      "Epoch 236/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0198\n",
      "Epoch 237/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0199\n",
      "Epoch 238/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 239/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0202\n",
      "Epoch 240/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0234\n",
      "Epoch 241/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0251 - val_loss: 0.9198 - val_mae: 0.0199\n",
      "Epoch 242/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "Epoch 243/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0222\n",
      "Epoch 244/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0234\n",
      "Epoch 245/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 246/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 247/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0229\n",
      "Epoch 248/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 249/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 250/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0243 - val_loss: 0.9198 - val_mae: 0.0224\n",
      "Epoch 251/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 252/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 253/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 254/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 255/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0247\n",
      "Epoch 256/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 257/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 258/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0202\n",
      "Epoch 259/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 260/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0226 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 261/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0229\n",
      "Epoch 262/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0204\n",
      "Epoch 263/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0214\n",
      "Epoch 264/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 265/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 266/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0247 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 267/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0225\n",
      "Epoch 268/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0206\n",
      "Epoch 269/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 270/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9198 - mae: 0.0221 - val_loss: 0.9198 - val_mae: 0.0216\n",
      "Epoch 271/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0193\n",
      "Epoch 272/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 273/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0194\n",
      "Epoch 274/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0197\n",
      "Epoch 275/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0226 - val_loss: 0.9199 - val_mae: 0.0226\n",
      "Epoch 276/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0252 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 277/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9198 - val_mae: 0.0204\n",
      "Epoch 278/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 279/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 280/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9204 - mae: 0.0255 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 281/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0199\n",
      "Epoch 282/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 283/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0238\n",
      "Epoch 284/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0249 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 285/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0223 - val_loss: 0.9198 - val_mae: 0.0222\n",
      "Epoch 286/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0200\n",
      "Epoch 287/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 288/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 289/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 290/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0222 - val_loss: 0.9199 - val_mae: 0.0227\n",
      "Epoch 291/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0216\n",
      "Epoch 292/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9199 - val_mae: 0.0210\n",
      "Epoch 293/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 294/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0247 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 295/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0225\n",
      "Epoch 296/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 297/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 298/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 299/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0227 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 300/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0224\n",
      "Epoch 301/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 302/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 303/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9198 - val_mae: 0.0229\n",
      "Epoch 304/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 305/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 306/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0219\n",
      "Epoch 307/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0193\n",
      "Epoch 308/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 309/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9198 - mae: 0.0218 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 310/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 311/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "Epoch 312/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0194\n",
      "Epoch 313/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0234\n",
      "Epoch 314/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 315/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0215\n",
      "Epoch 316/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 317/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 318/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0224\n",
      "Epoch 319/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 320/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 321/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 322/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 323/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 324/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 325/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 326/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 327/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0233\n",
      "Epoch 328/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 329/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 330/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9199 - val_mae: 0.0202\n",
      "Epoch 331/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0226 - val_loss: 0.9199 - val_mae: 0.0217\n",
      "Epoch 332/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 333/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0215\n",
      "Epoch 334/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0248 - val_loss: 0.9199 - val_mae: 0.0209\n",
      "Epoch 335/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 336/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 337/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 338/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 339/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "Epoch 340/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 341/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 342/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0224\n",
      "Epoch 343/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 344/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 345/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0202\n",
      "Epoch 346/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0227 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 347/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 348/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 349/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 350/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 351/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 352/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 353/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 354/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9198 - mae: 0.0219 - val_loss: 0.9198 - val_mae: 0.0215\n",
      "Epoch 355/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "Epoch 356/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 357/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0237\n",
      "Epoch 358/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0202\n",
      "Epoch 359/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0194\n",
      "Epoch 360/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0222\n",
      "Epoch 361/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0250 - val_loss: 0.9198 - val_mae: 0.0196\n",
      "Epoch 362/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0223 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 363/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0222\n",
      "Epoch 364/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0235\n",
      "Epoch 365/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 366/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0238\n",
      "Epoch 367/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0217\n",
      "Epoch 368/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0225 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 369/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9199 - val_mae: 0.0199\n",
      "Epoch 370/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0223 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "Epoch 371/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 372/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0204\n",
      "Epoch 373/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0217\n",
      "Epoch 374/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 375/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0224\n",
      "Epoch 376/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0195\n",
      "Epoch 377/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0207\n",
      "Epoch 378/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0224 - val_loss: 0.9198 - val_mae: 0.0232\n",
      "Epoch 379/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 380/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0199\n",
      "Epoch 381/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0195\n",
      "Epoch 382/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 383/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 384/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0222 - val_loss: 0.9198 - val_mae: 0.0203\n",
      "Epoch 385/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0225 - val_loss: 0.9199 - val_mae: 0.0224\n",
      "Epoch 386/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0194\n",
      "Epoch 387/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0194\n",
      "Epoch 388/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 389/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9199 - val_mae: 0.0202\n",
      "Epoch 390/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0222\n",
      "Epoch 391/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0204\n",
      "Epoch 392/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 393/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 394/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0227 - val_loss: 0.9200 - val_mae: 0.0239\n",
      "Epoch 395/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0256 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 396/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 397/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0224 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 398/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0235\n",
      "Epoch 399/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0195\n",
      "Epoch 400/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0225 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 401/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0200\n",
      "Epoch 402/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0222 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 403/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0227 - val_loss: 0.9198 - val_mae: 0.0196\n",
      "Epoch 404/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0220 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 405/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 406/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 407/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0239 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 408/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 409/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 410/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0223 - val_loss: 0.9198 - val_mae: 0.0245\n",
      "Epoch 411/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 412/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0227\n",
      "Epoch 413/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 414/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 415/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 416/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 417/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 418/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 419/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0221\n",
      "Epoch 420/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0206\n",
      "Epoch 421/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0229 - val_loss: 0.9198 - val_mae: 0.0198\n",
      "Epoch 422/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0243 - val_loss: 0.9199 - val_mae: 0.0215\n",
      "Epoch 423/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 424/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0194\n",
      "Epoch 425/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0216\n",
      "Epoch 426/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0225 - val_loss: 0.9198 - val_mae: 0.0196\n",
      "Epoch 427/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 428/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 429/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0208\n",
      "Epoch 430/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0224 - val_loss: 0.9198 - val_mae: 0.0216\n",
      "Epoch 431/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0245 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 432/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0227\n",
      "Epoch 433/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 434/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0226 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 435/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 436/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9200 - val_mae: 0.0205\n",
      "Epoch 437/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0222\n",
      "Epoch 438/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0209\n",
      "Epoch 439/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0217\n",
      "Epoch 440/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0230\n",
      "Epoch 441/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9198 - val_mae: 0.0220\n",
      "Epoch 442/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 443/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0240 - val_loss: 0.9199 - val_mae: 0.0190\n",
      "Epoch 444/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0227 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 445/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 446/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0227 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 447/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0221 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 448/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0204\n",
      "Epoch 449/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0225 - val_loss: 0.9198 - val_mae: 0.0227\n",
      "Epoch 450/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0199\n",
      "Epoch 451/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 452/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0199\n",
      "Epoch 453/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0230 - val_loss: 0.9198 - val_mae: 0.0229\n",
      "Epoch 454/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 455/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0198\n",
      "Epoch 456/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9199 - val_mae: 0.0194\n",
      "Epoch 457/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0218\n",
      "Epoch 458/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0229 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 459/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0228\n",
      "Epoch 460/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0234 - val_loss: 0.9199 - val_mae: 0.0203\n",
      "Epoch 461/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9203 - mae: 0.0248 - val_loss: 0.9199 - val_mae: 0.0200\n",
      "Epoch 462/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0212\n",
      "Epoch 463/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0213\n",
      "Epoch 464/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0223 - val_loss: 0.9198 - val_mae: 0.0215\n",
      "Epoch 465/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0241 - val_loss: 0.9198 - val_mae: 0.0220\n",
      "Epoch 466/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 467/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0240 - val_loss: 0.9198 - val_mae: 0.0235\n",
      "Epoch 468/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0207\n",
      "Epoch 469/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0201\n",
      "Epoch 470/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0224 - val_loss: 0.9198 - val_mae: 0.0228\n",
      "Epoch 471/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0213\n",
      "Epoch 472/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0240 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 473/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0245 - val_loss: 0.9198 - val_mae: 0.0217\n",
      "Epoch 474/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0236\n",
      "Epoch 475/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0236 - val_loss: 0.9198 - val_mae: 0.0211\n",
      "Epoch 476/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0233 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 477/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0237 - val_loss: 0.9198 - val_mae: 0.0226\n",
      "Epoch 478/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0232 - val_loss: 0.9199 - val_mae: 0.0254\n",
      "Epoch 479/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0235 - val_loss: 0.9198 - val_mae: 0.0197\n",
      "Epoch 480/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0204\n",
      "Epoch 481/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0239 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 482/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0243 - val_loss: 0.9198 - val_mae: 0.0195\n",
      "Epoch 483/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0223\n",
      "Epoch 484/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0232 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 485/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0235 - val_loss: 0.9199 - val_mae: 0.0194\n",
      "Epoch 486/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0247 - val_loss: 0.9198 - val_mae: 0.0238\n",
      "Epoch 487/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0208\n",
      "Epoch 488/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0228 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 489/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9202 - mae: 0.0238 - val_loss: 0.9199 - val_mae: 0.0215\n",
      "Epoch 490/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0210\n",
      "Epoch 491/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0221 - val_loss: 0.9198 - val_mae: 0.0227\n",
      "Epoch 492/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0236 - val_loss: 0.9199 - val_mae: 0.0221\n",
      "Epoch 493/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0242 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "Epoch 494/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0227 - val_loss: 0.9199 - val_mae: 0.0191\n",
      "Epoch 495/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0234 - val_loss: 0.9198 - val_mae: 0.0200\n",
      "Epoch 496/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0224 - val_loss: 0.9198 - val_mae: 0.0222\n",
      "Epoch 497/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0219\n",
      "Epoch 498/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9199 - mae: 0.0224 - val_loss: 0.9199 - val_mae: 0.0205\n",
      "Epoch 499/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9201 - mae: 0.0238 - val_loss: 0.9198 - val_mae: 0.0205\n",
      "Epoch 500/500\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9200 - mae: 0.0231 - val_loss: 0.9198 - val_mae: 0.0214\n",
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.9200 - mae: 0.0211\n",
      "Test Loss: 0.9201233386993408, Test MAE: 0.022418055683374405\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Mean Absolute Error as metric for regression\n",
    "\n",
    "# Train the Bayesian neural network\n",
    "history = model.fit(X_train, y_train, epochs=500,\n",
    "                    batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02175388],\n",
       "       [0.04035895],\n",
       "       [0.01766905],\n",
       "       ...,\n",
       "       [0.01886513],\n",
       "       [0.03965862],\n",
       "       [0.01877037]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.022418052371088907\n",
      "Mean Squared Error (MSE): 0.0023923244982281466\n",
      "Root Mean Squared Error (RMSE): 0.04891139435988456\n",
      "R-squared: 0.2280323094430008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mae = mean_absolute_error(y_test, prediction)\n",
    "mse = mean_squared_error(y_test, prediction)\n",
    "rmse = np.sqrt(mse)\n",
    "rsquared = r2_score(y_test, prediction)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared:\", rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a MinMaxScaler object named scalerX\n",
    "# original_Y_test = scalerY.inverse_transform(prediction)\n",
    "# original_Y_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the predicted values to their original scale\n",
    "# original_Y_test = scalerY.inverse_transform(prediction)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# predictions_df= pd.DataFrame(np.array(predictions),columns=Yreq)\n",
    "# Fseries=list(predictions_df.columns)\n",
    "# print(len(Fseries))\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(len(Y_val)):\n",
    "#     plt.scatter(y_test[:, i], predictions[:, i], label=Y_val[i])\n",
    "# plt.xlabel('Actual Values')\n",
    "# plt.ylabel('Predicted Values')\n",
    "# plt.xscale(\"log\")\n",
    "# plt.yscale(\"log\")\n",
    "# plt.title('Predictions vs Actual Values')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
