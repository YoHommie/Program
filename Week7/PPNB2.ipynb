{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.logging.TaskLevelStatusMessage is deprecated. Please use tf.compat.v1.logging.TaskLevelStatusMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_probability\\python\\internal\\backend\\numpy\\_utils.py:48: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '6' to a shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     59\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m Sequential([\n\u001b[0;32m     60\u001b[0m       tfpl\u001b[38;5;241m.\u001b[39mVariableLayer(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m n, dtype\u001b[38;5;241m=\u001b[39mdtype),\n\u001b[0;32m     61\u001b[0m       tfpl\u001b[38;5;241m.\u001b[39mDistributionLambda(\u001b[38;5;28;01mlambda\u001b[39;00m t: tfpd\u001b[38;5;241m.\u001b[39mIndependent(\n\u001b[0;32m     62\u001b[0m           tfpd\u001b[38;5;241m.\u001b[39mNormal(loc\u001b[38;5;241m=\u001b[39mt[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :n],\n\u001b[0;32m     63\u001b[0m                      scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftplus(c \u001b[38;5;241m+\u001b[39m t[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, n:])),\n\u001b[0;32m     64\u001b[0m           reinterpreted_batch_ndims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)),])\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Initializing the network\u001b[39;00m\n\u001b[0;32m     67\u001b[0m West2_PBNN \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m---> 68\u001b[0m     \u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;66;03m#Input layer\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     tfpl\u001b[38;5;241m.\u001b[39mDenseVariational(  \u001b[38;5;66;03m#Probabilistic layer\u001b[39;00m\n\u001b[0;32m     70\u001b[0m         units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m     71\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_var_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     72\u001b[0m         make_prior_fn\u001b[38;5;241m=\u001b[39mprior,\n\u001b[0;32m     73\u001b[0m         make_posterior_fn\u001b[38;5;241m=\u001b[39mposterior_mean_field,\n\u001b[0;32m     74\u001b[0m         kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m203\u001b[39m,\n\u001b[0;32m     75\u001b[0m        activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     76\u001b[0m     tfpl\u001b[38;5;241m.\u001b[39mDenseVariational(   \u001b[38;5;66;03m#Probabilistic layer\u001b[39;00m\n\u001b[0;32m     77\u001b[0m         units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m     78\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_var_2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m         make_prior_fn\u001b[38;5;241m=\u001b[39mprior,\n\u001b[0;32m     80\u001b[0m         make_posterior_fn\u001b[38;5;241m=\u001b[39mposterior_mean_field,\n\u001b[0;32m     81\u001b[0m         kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m203\u001b[39m,\n\u001b[0;32m     82\u001b[0m         activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     83\u001b[0m     Dense(units\u001b[38;5;241m=\u001b[39mtfpl\u001b[38;5;241m.\u001b[39mIndependentNormal\u001b[38;5;241m.\u001b[39mparams_size(\u001b[38;5;241m29\u001b[39m),name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;66;03m#output is mean and standard deviation of targets\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     tfpl\u001b[38;5;241m.\u001b[39mDistributionLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tfpd\u001b[38;5;241m.\u001b[39mIndependent(tfpd\u001b[38;5;241m.\u001b[39mNormal(loc \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m29\u001b[39m], scale \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftplus( x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m29\u001b[39m:]))),name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m   ], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBNN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     87\u001b[0m West2_PBNN\u001b[38;5;241m.\u001b[39mcompile(keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m),loss\u001b[38;5;241m=\u001b[39mNLL, metrics\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mMeanSquaredError())\n\u001b[0;32m     89\u001b[0m Sub_PBNN \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     90\u001b[0m     Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m)),\n\u001b[0;32m     91\u001b[0m     tfpl\u001b[38;5;241m.\u001b[39mDenseVariational(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     tfpl\u001b[38;5;241m.\u001b[39mDistributionLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: tfpd\u001b[38;5;241m.\u001b[39mIndependent(tfpd\u001b[38;5;241m.\u001b[39mNormal(loc \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :\u001b[38;5;241m29\u001b[39m], scale \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftplus( x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m29\u001b[39m:]))),name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    107\u001b[0m   ], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPBNN\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:143\u001b[0m, in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, dtype, sparse, batch_shape, name, tensor)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.layers.Input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.Input\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mInput\u001b[39m(\n\u001b[0;32m     91\u001b[0m     shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     98\u001b[0m ):\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used to instantiate a Keras tensor.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    A Keras tensor is a symbolic tensor-like object, which we augment with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mInputLayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:46\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, name, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass a `shape` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m (batch_size,) \u001b[38;5;241m+\u001b[39m shape\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(batch_shape)\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:442\u001b[0m, in \u001b[0;36mstandardize_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndefined shapes are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(shape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;66;03m# `tf.TensorShape` may contain `Dimension` objects.\u001b[39;00m\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;66;03m# We need to convert the items in it to either int or `None`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert '6' to a shape."
     ]
    }
   ],
   "source": [
    "# Load required libraries which we use\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import Input, models, layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Input\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "tfpl = tfp.layers\n",
    "tfpd = tfp.distributions\n",
    "\n",
    "#Compute mean and standard deviation to normalize the inputs and targets\n",
    "West2_Input_mean = np.array([5.729923, 4.413790, 10.152883, 5.998398, 2.012284, 2.037392])\n",
    "West2_Input_std = np.array([1.20254254, 0.9451266 , 3.82392659, 0.40372298, 0.97509672, 1.24592341])\n",
    "West2_Target_mean = np.array([-4.87994126, -0.40750808, -1.5720524 , -4.87129283, -4.86554322,\n",
    "       -4.83396755, -4.78392878, -4.71804622, -4.64194504, -4.52477363,\n",
    "       -4.42237238, -4.36390945, -4.17157297, -4.10993212, -4.14920651,\n",
    "       -4.27740031, -4.42336678, -4.570936  , -4.71155478, -4.78408848,\n",
    "       -4.85785709, -4.99490487, -5.12360358, -5.3604136 , -5.67051165,\n",
    "       -6.1146535 , -6.48955253, -6.79227626, -7.27018767])\n",
    "West2_Target_std = np.array([2.42715374, 2.60588243, 3.11510912, 2.42484311, 2.43051757,\n",
    "       2.43493243, 2.44403298, 2.45402093, 2.46459099, 2.4795051 ,\n",
    "       2.48593953, 2.48862045, 2.45871136, 2.4408254 , 2.42881608,\n",
    "       2.43069125, 2.45164507, 2.47593218, 2.51209384, 2.52887418,\n",
    "       2.54547056, 2.5741994 , 2.60329123, 2.65998072, 2.73565873,\n",
    "       2.84012449, 2.91487773, 2.9793393 , 3.08117291])\n",
    "\n",
    "Sub_Input_mean = np.array([6.68478357, 5.17778629, 52.52107701, 6.03977884, 2.58125892, 3.52600285])\n",
    "Sub_Input_std = np.array([1.07637091, 0.70259695, 33.92583053, 0.4649875, 0.70112263, 1.04375727])\n",
    "Sub_Target_mean = np.array([-4.62930168, -0.09396118, -0.87646346, -4.62512346, -4.61123033,\n",
    "       -4.57654343, -4.51962872, -4.44320954, -4.3557332 , -4.22339103,\n",
    "       -4.10980331, -4.04542538, -3.87901567, -3.84546682, -3.91578905,\n",
    "       -4.02926474, -4.15708557, -4.2799341 , -4.40100951, -4.46213172,\n",
    "       -4.51942888, -4.63836273, -4.74801388, -4.95690246, -5.24014924,\n",
    "       -5.65133563, -5.99135529, -6.28249356, -6.76874589])\n",
    "Sub_Target_std = np.array([2.27127476, 2.13369015, 2.53483697, 2.27242527, 2.27640746,\n",
    "       2.28640393, 2.30366638, 2.32003444, 2.33673787, 2.36636804,\n",
    "       2.38607502, 2.39422058, 2.38914363, 2.36506948, 2.32110199,\n",
    "       2.28934885, 2.25629222, 2.23293288, 2.2116741 , 2.20308297,\n",
    "       2.19585583, 2.1842407 , 2.17238935, 2.15886921, 2.15639852,\n",
    "       2.15997677, 2.17487696, 2.1878803 , 2.21326018])\n",
    "\n",
    "# Defining Gaussian prior to all the layers with zero mean and unit standard deviation\n",
    "def prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return Sequential([tfpl.DistributionLambda(lambda t: tfpd.MultivariateNormalDiag(loc=tf.zeros(n), scale_diag=tf.ones(n)))])\n",
    "\n",
    "# Defining loss function\n",
    "def NLL(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)\n",
    "\n",
    "# We use posterior mean field assumption\n",
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  c = np.log(np.expm1(1.))\n",
    "  return Sequential([\n",
    "      tfpl.VariableLayer(2 * n, dtype=dtype),\n",
    "      tfpl.DistributionLambda(lambda t: tfpd.Independent(\n",
    "          tfpd.Normal(loc=t[..., :n],\n",
    "                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1)),])\n",
    "\n",
    "# Initializing the network\n",
    "West2_PBNN = Sequential([\n",
    "    Input(shape=(6)), #Input layer\n",
    "    tfpl.DenseVariational(  #Probabilistic layer\n",
    "        units=7,\n",
    "        name=\"dense_var_1\",\n",
    "        make_prior_fn=prior,\n",
    "        make_posterior_fn=posterior_mean_field,\n",
    "        kl_weight=1/203,\n",
    "       activation='sigmoid'),\n",
    "    tfpl.DenseVariational(   #Probabilistic layer\n",
    "        units=7,\n",
    "        name=\"dense_var_2\",\n",
    "        make_prior_fn=prior,\n",
    "        make_posterior_fn=posterior_mean_field,\n",
    "        kl_weight=1/203,\n",
    "        activation='sigmoid'),\n",
    "    Dense(units=tfpl.IndependentNormal.params_size(29),name='output'), #output is mean and standard deviation of targets\n",
    "    tfpl.DistributionLambda(lambda x: tfpd.Independent(tfpd.Normal(loc = x[..., :29], scale = tf.nn.softplus( x[..., 29:]))),name='lambda')\n",
    "  ], name='PBNN')\n",
    "\n",
    "West2_PBNN.compile(keras.optimizers.Adam(learning_rate=0.01),loss=NLL, metrics=keras.metrics.MeanSquaredError())\n",
    "\n",
    "Sub_PBNN = Sequential([\n",
    "    Input(shape=(6)),\n",
    "    tfpl.DenseVariational(\n",
    "        units=7,\n",
    "        name=\"dense_var_1\",\n",
    "        make_prior_fn=prior,\n",
    "        make_posterior_fn=posterior_mean_field,\n",
    "        kl_weight=1/136.965625,\n",
    "       activation='sigmoid'),\n",
    "    tfpl.DenseVariational(\n",
    "        units=7,\n",
    "        name=\"dense_var_2\",\n",
    "        make_prior_fn=prior,\n",
    "        make_posterior_fn=posterior_mean_field,\n",
    "        kl_weight=1/136.965625,\n",
    "        activation='sigmoid'),\n",
    "    Dense(units=tfpl.IndependentNormal.params_size(29),name='output'),\n",
    "    tfpl.DistributionLambda(lambda x: tfpd.Independent(tfpd.Normal(loc = x[..., :29], scale = tf.nn.softplus( x[..., 29:]))),name='lambda')\n",
    "  ], name='PBNN')\n",
    "\n",
    "#Adam optimizer, with MSE metric\n",
    "Sub_PBNN.compile(keras.optimizers.Adam(learning_rate=0.01),loss=NLL, metrics=keras.metrics.MeanSquaredError())\n",
    "\n",
    "West2_PBNN.load_weights('SR22_West2_PBNN.h5') #Load the pretrained weights to the network\n",
    "Sub_PBNN.load_weights('SR22_Sub_PBNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper Title: \"Stochastic ground motion models to NGA-West2 and NGASub databases using Bayesian neural network\"\n",
    "# Code developed by: Sreenath Vemula, Raghukanth STG\n",
    "\n",
    "# Email: vsreenath2@gmail.com\n",
    "\n",
    "# Submitted to: Earthquake Engineering and Structural Dynamics journal\n",
    "\n",
    "### Initialize networks\n",
    "\n",
    "# Before which, load SR22_West2_PBNN and SR22_Sub_PBNN files\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"### Inputs\"\"\"\n",
    "\n",
    "Case = int(input(\"Enter database (1: NGA-West2, 2: NGA-Sub): \"))\n",
    "######## NGA West2 Model Applicability ########\n",
    "#Mw : 3.3 – 7.9 (R=1), 5.1 – 7.9 (R=2), 5.9 – 7.6 (R=3), and 6.2 – 7 (R=4) \n",
    "#Rrup: < 175 km (R=3),  < 400 km (otherwise). Zhyp < 25 km, Vs30: 90 – 2000 m/s. \n",
    "\n",
    "######## NGA Sub Model Applicability ########\n",
    "#Mw : 4.5 – 8 (R=1), 4 – 7.1 (R=3), 5 – 9.1 (R=4), and 5.7 – 8.8 (R=5) \n",
    "#Rrup : 30 – 1000 km (R=1), 32 – 670 km (R=3), 8.3 – 929 (R=4), and 13 – 1000 km (R=5).\n",
    "#Zhyp : 3 – 40 km (interface) and 20 – 180 km (intraslab). Vs30 : 90 – 2200 m/s. \n",
    "\n",
    "Mw = float(input(\"Enter magnitude: \"))\n",
    "Rrup = float(input(\"Enter rupture distance (km): \"))\n",
    "Zhyp = float(input(\"Enter rupture depth (km): \"))\n",
    "Vs30 = float(input(\"Enter shear wave velocity (m/s): \"))\n",
    "print('Fault flag for both the regions')\n",
    "print('1: Strike-slip, 2: Normal or Normal-oblique, 3: Reverse or Reverse-oblique')\n",
    "F = int(input(\"Enter fault flag: \"))\n",
    "if Case == 1:\n",
    "  print('Region flag For NGA-West2 region')\n",
    "  print('1. Alaska, California    2: China, Greece, Iran, Italy, Turkey, USSR')\n",
    "  print('3. Taiwan                4: Japan, New Zealand')\n",
    "if Case == 2:\n",
    "  print('Region flag For NGA-Sub region')\n",
    "  print('1. Alaska, Cascadia      5: Mexico, Central and South America')\n",
    "  print('3. Taiwan                4: Japan, New Zealand')\n",
    "R = int(input(\"Enter region flag: \"))\n",
    "Inputs = np.array([Mw, np.log(Rrup), Zhyp, np.log(Vs30), F, R])\n",
    "if Case == 1:\n",
    "  Input_norm = np.expand_dims(np.divide(Inputs - West2_Input_mean,West2_Input_std),1).T\n",
    "if Case == 2:\n",
    "  Input_norm = np.expand_dims(np.divide(Inputs - Sub_Input_mean,Sub_Input_std),1).T\n",
    "\n",
    "\n",
    "\"\"\"### Output\"\"\"\n",
    "\n",
    "count = 100 #number of iterations the network is to be run\n",
    "y_mean = []\n",
    "y_std = []\n",
    "for _ in range(count):\n",
    "  if Case == 1:\n",
    "    out_dist = West2_PBNN(Input_norm) #network prediction, which is the distribution\n",
    "    y_mean.append(tf.cast(out_dist.mean(), tf.float64) * West2_Target_std + West2_Target_mean)  #denormalization of the output\n",
    "    y_std.append(tf.cast(out_dist.stddev(), tf.float64) * West2_Target_std) #denormalization of the deviations\n",
    "  if Case == 2:\n",
    "    out_dist = Sub_PBNN(Input_norm)\n",
    "    y_mean.append(tf.cast(out_dist.mean(), tf.float64) * Sub_Target_std + Sub_Target_mean)\n",
    "    y_std.append(tf.cast(out_dist.stddev(), tf.float64) * Sub_Target_std)\n",
    "aleatoric_std = np.mean(y_std,axis=0)     #computing aleatory variability\n",
    "epistemic_std = np.std(y_mean, axis=0)    #computing epistemic uncertainty\n",
    "output = np.mean(y_mean, axis=0)  #predicted output of the network\n",
    "print('Aleatoric')\n",
    "print(aleatoric_std)\n",
    "print('Epistemic')\n",
    "print(epistemic_std)\n",
    "print('Mean Prediction')\n",
    "print(np.exp(output))\n",
    "periods = [0.01,0.02,0.03,0.04,0.05,0.06,0.075,0.09,0.1,0.15,0.2,0.3,0.4,0.5,0.6,0.7,0.75,0.8,0.9,1,1.2,1.5,2,2.5,3,4]\n",
    "fig, ax = plot.subplots(1,1,figsize=(7,5))\n",
    "lower_bound = np.squeeze(np.exp(output - 1.96*epistemic_std)[:,3:],axis=0)\n",
    "upper_bound = np.squeeze(np.exp(output + 1.96*epistemic_std)[:,3:],axis=0)\n",
    "ax.fill_between(periods, lower_bound, upper_bound, color='b', label='Epistemic Uncertainty', alpha=.2)\n",
    "lower_bound = np.squeeze(np.exp(output - 1.96*aleatoric_std)[:,3:],axis=0)\n",
    "upper_bound = np.squeeze(np.exp(output + 1.96*aleatoric_std)[:,3:],axis=0)\n",
    "ax.fill_between(periods, lower_bound, upper_bound, color='c', label='Aleatory Variability', alpha=.2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.plot(periods,tf.math.exp(tf.squeeze(output,axis=0)[3:]), '--', color='k', label='Mean Prediction', linewidth=1.5)\n",
    "ax.set_xlabel(\"Period (s)\")\n",
    "ax.set_ylabel(\"$\\mathregular{S_a}$ (g)\")\n",
    "ax.legend()\n",
    "plot.title('Mean prediction with 95% probability intervals')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
