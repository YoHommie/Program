{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import autograd\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CGAN_B_GENERATOR_PATH = \"/content/drive/MyDrive/Seismic/Saved Models/CGAN_bg_model.df5\"\n",
    "\n",
    "CGAN_B_DISCRIMINATOR_PATH = \"/content/drive/MyDrive/Seismic/Saved Models/CGAN_bd_model.hdf5\"\n",
    "CGAN_GENERATOR_PATH = \"/content/drive/MyDrive/Seismic/Saved Models/CGAN_g_model.df5\"\n",
    "CGAN_DISCRIMINATOR_PATH = \"/content/drive/MyDrive/Seismic/Saved Models/CGAN_d_model.hdf5\"\n",
    "res = \"/content/drive/MyDrive/Seismic/results.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # Make device agnostic code\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df_org\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropping rows with blank data (Point 1)\n",
    "df.drop(df[df['Joyner-Boore Dist. (km)'] == -999].index, inplace = True)\n",
    "df.drop(df[df['Depth Used (km)'] == -999].index, inplace = True)\n",
    "# df.drop(df[df['Hypocenter Depth (km)'] == -999].index, inplace = True)\n",
    "df.drop(df[df['Preferred VS30 (m/sec)'] == -999].index, inplace = True)\n",
    "# Dropping rows with RJB > 1500km (Point 3)\n",
    "df.drop(df[df['Joyner-Boore Dist. (km)'] > 1500].index, inplace = True)\n",
    "# Removing questionable Hypocentral Distance (Point 5)\n",
    "df.drop(df[df['HypD (km)'] <= 0].index, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.reset_index()\n",
    "res = ['_PGA', '_PGV', 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 2.5, 3, 4]\n",
    "3\n",
    "PSA_tp = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.15, 0.2,0.25, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 2.5, 3, 4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Create the MinMaxScaler object\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_cond = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_real = pd.DataFrame()\n",
    "X_real['Mw'] = df['Earthquake Magnitude']\n",
    "# X['Rjb'] = df['Joyner-Boore Dist. (km)']\n",
    "X_real['logRjb'] = np.log10(df['Joyner-Boore Dist. (km)'])\n",
    "# X['Mw/Rjb'] = df_lr['Mw']/df_lr['Rjb']\n",
    "# X['focal'] = df['ClstD (km)']\n",
    "X_real['Vs30'] = df['Preferred VS30 (m/sec)']\n",
    "X_real['PSA_PGA'] = np.log10(df['PGA-H RotDnn (g)'])\n",
    "X_real['PSA_PGV'] = np.log10(df['PGV-H RotDnn (cm/s)'])\n",
    "for i in PSA_tp:X_real[f'PSA{i}'] = np.log10(df[f'T{i}s'])\n",
    "X_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_temp = train_test_split(X_real, test_size=0.3)\n",
    "X_val, X_test = train_test_split(X_test_temp, test_size=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_cond_temp = pd.DataFrame(scaler_cond.fit_transform(X_real[['Mw', 'logRjb', 'Vs30']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_real))\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(31, 50),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(50, 80),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(80, 100),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Linear(100, 1),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x, c, batch_size):\n",
    "        # x = torch.from_numpy(x)\n",
    "        # c = torch.from_numpy(c)\n",
    "        c = c.view(batch_size, -1)\n",
    "        x = x.view(x.size(0), 28)\n",
    "        x = torch.cat((x, c), 1)\n",
    "        out = self.model(x.to(torch.float32))\n",
    "        return out.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(13, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(64, 45),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(45, 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, c, batch_size):\n",
    "        # z = torch.from_numpy(z)\n",
    "        # c = torch.from_numpy(c)\n",
    "        # c = np.array(c)\n",
    "        # c = c.view(batch_size, -1)\n",
    "        c = c.reshape(batch_size, -1)\n",
    "        z = z.view(batch_size, 10)\n",
    "        x = torch.cat((z, c), 1)\n",
    "        out = self.model(x.to(torch.float32))\n",
    "        return out.view(x.size(0), 28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_real_samples(df_real, n):\n",
    "    df_sample = df_real.sample(n)\n",
    "    X1 = torch.from_numpy(df_sample[[0, 1, 2]].values)\n",
    "    X2 = torch.from_numpy(df_sample[[i for i in range(3,31)]].values)\n",
    "    # X1 = torch.from_numpy(df_sample[['Mw', 'logRjb', 'Vs30']].values)\n",
    "    # X2 = torch.from_numpy(df_sample[[f'PSA{i}' for i in res]].values)\n",
    "    7\n",
    "    # X = torch.hstack((X1, X2))\n",
    "    # y = torch.ones((n, 1))\n",
    "    X1 = X1.to(device)\n",
    "    X2 = X2.to(device)\n",
    "    return X2, X1\n",
    "def generate_latent_points(latent_dim, n_conditions, batch_size, data):\n",
    "    z_vector = np.random.randn(latent_dim * batch_size)\n",
    "    z_vector = torch.from_numpy(z_vector)\n",
    "    # cond = data.sample(batch_size)[[0, 1, 2]].values\n",
    "    # cond = data.sample(batch_size)[['Mw', 'logRjb', 'Vs30']].values\n",
    "    z_vector = z_vector.reshape(batch_size, latent_dim)\n",
    "    z_vector = z_vector.to(device)\n",
    "    return z_vector\n",
    "def generate_fake_samples(generator, latent_dim, n_conditions, batch_size,\n",
    "data):\n",
    "    z_vector = generate_latent_points(latent_dim, n_conditions, batch_size, data)\n",
    "    cond = np.random.randn(n_conditions * batch_size)\n",
    "    cond = torch.from_numpy(cond)\n",
    "    z_vector = z_vector.to(device)\n",
    "    cond = cond.to(device)\n",
    "    X = generator(z_vector, cond, batch_size)\n",
    "    # X = torch.cat((z_vector, cond), 1)\n",
    "    # y = torch.zeros((batch_size, 1))\n",
    "    # X = X.to(device)\n",
    "    # y = y.to(device)\n",
    "    return X, cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define your loss function (e.g., binary cross-entropy)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "# criterion = nn.MSELoss().to(device)\n",
    "torch.set_grad_enabled(True)\n",
    "# Define your optimizer (e.g., Adam optimizer)\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "dis_optimizer = optim.Adam(discriminator.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator.load_state_dict(torch.load(CGAN_B_GENERATOR_PATH))\n",
    "discriminator.load_state_dict(torch.load(CGAN_B_DISCRIMINATOR_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i=0\n",
    "with open(res, mode ='r')as file:csvFile = csv.reader(file)\n",
    "for lines in csvFile:\n",
    "    i+=1\n",
    "    if i==10000:\n",
    "        latest = lines\n",
    "float(str(latest[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.auto import tqdm\n",
    "def predict(conditions_test, generator, device):\n",
    "    generator.eval() # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Generate noise vector\n",
    "        input = np.random.randn(10 * conditions_test.shape[0])\n",
    "        input = torch.from_numpy(input)\n",
    "        input = input.to(device)\n",
    "        conditions_test = torch.from_numpy(conditions_test)\n",
    "        conditions_test = conditions_test.to(device)\n",
    "        # Generate outputs\n",
    "        predicted_outputs = generator(input, conditions_test, conditions_test.shape[0])\n",
    "        9\n",
    "        predicted_outputs = torch.cat((conditions_test, predicted_outputs), 1)\n",
    "    return predicted_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(g_model, d_model, data, val_data, latent_dim, n_epochs = 30000,n_batch = 128, best_r2=-100000):\n",
    "    batch_per_epoch = int(data.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch/2)\n",
    "    y_real = torch.ones((64, 1))\n",
    "    y_fake = torch.zeros((64, 1))\n",
    "    y_real = y_real.to(device)\n",
    "    y_fake = y_fake.to(device)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(batch_per_epoch):\n",
    "            data_real, cond_real = generate_real_samples(data, half_batch)\n",
    "            data_fake, cond_fake = generate_fake_samples(generator, latent_dim, 3,half_batch, data)\n",
    "            data_real = data_real.to(device)\n",
    "            # y_real = y_real.to(device)\n",
    "            data_fake = data_fake.to(device)\n",
    "            # y_fake = y_fake.to(device)\n",
    "            d_model.zero_grad()\n",
    "            # Fake\n",
    "            fake_output = discriminator(data_fake, cond_fake, half_batch)\n",
    "            # print(fake_output, y_fake)\n",
    "            fake_output = fake_output.to(device)\n",
    "            d_total_loss = 0\n",
    "            d_loss = criterion(fake_output, y_fake.squeeze())\n",
    "            d_total_loss+=d_loss\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            dis_optimizer.step()\n",
    "            # Real\n",
    "            real_output = discriminator(data_real, cond_real, half_batch)\n",
    "            real_output = real_output.to(device)\n",
    "            d_loss = criterion(real_output, y_real.squeeze())\n",
    "            d_total_loss+=d_loss\n",
    "            10\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            dis_optimizer.step()\n",
    "            # d_loss = d_loss_real + d_loss_fake\n",
    "            # d_loss.backward(retain_graph=True)\n",
    "            # dis_optimizer.step()\n",
    "            # Training the generator\n",
    "            generator.zero_grad()\n",
    "            fake_output = discriminator(data_fake, cond_fake, half_batch)\n",
    "            # print(fake_output, y_real)\n",
    "            g_loss = criterion(fake_output, y_real.squeeze())\n",
    "            g_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "            # Print training stats\n",
    "            if j % 100 == 0 and i%100 == 0:\n",
    "                print('[%d/%d][%d/%d] Loss_D: %.10f || Loss_G: %.10f' % (i, n_epochs,j, batch_per_epoch, d_total_loss.item(), g_loss.item()))\n",
    "        X_val_temp = pd.DataFrame(scaler.transform(val_data))\n",
    "        conditions_val = X_val_temp[[0, 1, 2]]\n",
    "        conditions_val = conditions_val.to_numpy()\n",
    "        pred_outputs = predict(conditions_val, generator, device)\n",
    "        true_values = scaler.inverse_transform(X_val_temp)\n",
    "        pred_outputs = scaler.inverse_transform(pred_outputs)\n",
    "        curr_r_squared_test = r2_score(true_values, pred_outputs)\n",
    "        torch.save(generator.state_dict(), CGAN_GENERATOR_PATH)\n",
    "        torch.save(discriminator.state_dict(), CGAN_DISCRIMINATOR_PATH)\n",
    "        if(curr_r_squared_test > best_r2):\n",
    "            torch.save(generator.state_dict(), CGAN_B_GENERATOR_PATH)\n",
    "            torch.save(discriminator.state_dict(), CGAN_B_DISCRIMINATOR_PATH)\n",
    "            best_r2 = curr_r_squared_test\n",
    "        res_ls = [i, best_r2, curr_r_squared_test, d_total_loss.item(), g_loss.\n",
    "        item()]\n",
    "        with open(res,'a') as fd:\n",
    "            writer = csv.writer(fd)\n",
    "            writer.writerow(res_ls)\n",
    "            # fd.write(str(curr_r_squared_test))\n",
    "        if i%100 == 0:\n",
    "            print(f'Validation r2 Score: {curr_r_squared_test} || Best r2 Score:{best_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train(generator, discriminator, data = X_train, val_data = X_val, latent_dim= 10, n_epochs = 50000, best_r2 = float(latest[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test_temp = pd.DataFrame(scaler.transform(X_test))\n",
    "true_values = scaler.inverse_transform(X_test_temp)\n",
    "conditions_test = X_test_temp[[0, 1, 2]]\n",
    "conditions_test = conditions_test.to_numpy()\n",
    "X_test_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator.load_state_dict(torch.load(CGAN_GENERATOR_PATH))\n",
    "discriminator.load_state_dict(torch.load(CGAN_DISCRIMINATOR_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(conditions_test, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)  \n",
    "mean_array = np.mean(mean_output, axis=0)\n",
    "mean_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate R-squared for test data\n",
    "r_squared_test = r2_score(true_values, mean_array)\n",
    "r_squared_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_values = true_values[:,5:]\n",
    "mean_array = mean_array[:,5:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel(r'$y-rec$')\n",
    "plt.ylabel(r'$y-pred$')\n",
    "#plt.scatter(X_test.data.numpy(), y_test.data.numpy(), color='k', s=2)\n",
    "#serial = range(0,37)\n",
    "# serial = 20\n",
    "# XX = y_test_tensor[:, serial].data.numpy()\n",
    "XX = true_values\n",
    "YY = mean_array\n",
    "# YY = mean_prediction[:, ser\n",
    "plt.scatter(XX, YY, color='r', s=10)\n",
    "#plt.scatter( y_test,y_predict.data.numpy(), color='r', s=10)\n",
    "min_val = min(np.min(XX), np.min(YY))\n",
    "max_val = max(np.max(XX), np.max(YY))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--',label='r2=0.75')\n",
    "plt.title('R2 Plot')\n",
    "plt.ylabel('Rec-test')\n",
    "plt.xlabel('Pre-test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_temp = pd.DataFrame(X_train)\n",
    "true_values = scaler.inverse_transform(X_train_temp)\n",
    "conditions_train = X_train_temp[[0, 1, 2]]\n",
    "conditions_train = conditions_train.to_numpy()\n",
    "X_train_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(conditions_train, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)\n",
    "mean_array = np.mean(mean_output, axis=0)\n",
    "mean_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate R-squared for train data\n",
    "r_squared_test = r2_score(true_values, mean_array)\n",
    "r_squared_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_values = true_values[:,5:]\n",
    "mean_array = mean_array[:,5:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.xlabel(r'$y-rec$')\n",
    "plt.ylabel(r'$y-pred$')\n",
    "#plt.scatter(X_train.data.numpy(), y_train.data.numpy(), color='k', s=2)\n",
    "#serial = range(0,37)\n",
    "# serial = 20\n",
    "# XX = y_train_tensor[:, serial].data.numpy()\n",
    "XX = true_values\n",
    "YY = mean_array\n",
    "# YY = mean_prediction[:, ser\n",
    "plt.scatter(XX, YY, color='r', s=10)\n",
    "#plt.scatter( y_train,y_predict.data.numpy(), color='r', s=10)\n",
    "min_val = min(np.min(XX), np.min(YY))\n",
    "max_val = max(np.max(XX), np.max(YY))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='black', linestyle='--',label='r2=0.76')\n",
    "plt.title('R2 Plot')\n",
    "plt.ylabel('Rec-train')\n",
    "plt.xlabel('Pre-train')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn.model_selection as sk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = df['USGS Potentially Induced Event (PIE) Flag'] == True\n",
    "inter = df[mask]\n",
    "intra = df[~mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inter.reset_index(inplace = True)\n",
    "intra.reset_index(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inter['Mw/Rjb'] = np.array(inter['Earthquake Magnitude']) / np.array(inter['Joyner-Boore Dist. (km)'])\n",
    "inter['log Rjb'] = np.log10(inter['Joyner-Boore Dist. (km)'])\n",
    "yy = pd.DataFrame()\n",
    "yy['log PGA'] = np.log10(inter['PGA-H RotDnn (g)'])\n",
    "yy['log PGV'] = np.log10(inter['PGV-H RotDnn (cm/s)'])\n",
    "t = [0.01 , 0.02 , 0.03 , 0.04 , 0.05,0.06 ,0.07 , 0.08 ,0.09,0.1,0.2 , 0.3 , 0.4, 0.5 ,0.6, 0.7,0.8,0.9,1,2,3,4,5]\n",
    "for i in t:\n",
    "    yy[f\"log PSA {i}s\"] = np.log10(inter[f\"T{i}s\"])\n",
    "XX = inter[['Earthquake Magnitude', 'Joyner-Boore Dist. (km)', 'log Rjb','Mechanism Based on Rake Angle', 'Preferred VS30 (m/sec)']]\n",
    "# XX = inter[['Earthquake Magnitude', 'log Rjb', 'Preferred VS30 (m/sec)']]\n",
    "# x_train1, x_test1, y_train1, y_test1 = sk.train_test_split(XX, yy, test_size= 0.15, random_state = 42)\n",
    "# x_test1, x_val1, y_test1, y_val1 = sk.train_test_split(x_test1, y_test1,test_size = 0.5, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions_inter = XX[['Earthquake Magnitude', 'log Rjb', 'Preferred VS30 (m/sec)']]\n",
    "conditions_inter = conditions_inter.to_numpy()\n",
    "conditions_inter_pred = scaler_cond.transform(conditions_inter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(conditions_inter_pred, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)\n",
    "inter_y_pred = np.mean(mean_output, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "residue_inter = yy - inter_y_pred[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XX['Joyner-Boore Dist. (km)'].max() - XX['Joyner-BooreDist. (km)'].min()) / 200) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Rjb (km)'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = i * 200\n",
    "    end_dist = start_dist + 200\n",
    "    intervals_X = XX[(XX['Joyner-Boore Dist. (km)'] >= start_dist) &(XX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Joyner-Boore Dist. (km)'] >= start_dist) &(XX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    41\n",
    "    residue_intervals = interval_data['log PSA 0.01s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Rjb (km)']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Rjb (km)\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Rjb (km)\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.01s) vs Rjb(km)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XX['Joyner-Boore Dist. (km)'].max() - XX['Joyner-BooreDist. (km)'].min()) / 200) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Rjb (km)'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = i * 200\n",
    "    end_dist = start_dist + 200\n",
    "    intervals_X = XX[(XX['Joyner-Boore Dist. (km)'] >= start_dist) &(XX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Joyner-Boore Dist. (km)'] >= start_dist) &(XX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PSA 0.2s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Rjb (km)']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Rjb (km)\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Rjb (km)\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.2s) vs Rjb(km)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XX['Joyner-Boore Dist. (km)'].max() - XX['Joyner-BooreDist. (km)'].min()) / 200) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Rjb (km)'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = i * 200\n",
    "    end_dist = start_dist + 200\n",
    "    intervals_X = XX[(XX['Joyner-Boore Dist. (km)'] >= start_dist) &(XX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Joyner-Boore Dist. (km)'] >= start_dist) &(XX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PGA']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Rjb (km)']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Rjb (km)\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Rjb (km)\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PGA Residual vs Rjb(km)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XX['Earthquake Magnitude'].max() - XX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XX[(XX['Earthquake Magnitude'] >= start_dist) & (XX['EarthquakeMagnitude'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Earthquake Magnitude'] >= start_dist) &(XX['Earthquake Magnitude'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PSA 0.01s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.01s) vs Mw')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XX['Earthquake Magnitude'].max() - XX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XX[(XX['Earthquake Magnitude'] >= start_dist) & (XX['EarthquakeMagnitude'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Earthquake Magnitude'] >= start_dist) &(XX['Earthquake Magnitude'] < end_dist)]\n",
    "    46\n",
    "    residue_intervals = interval_data['log PSA 0.2s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.2s) vs Mw')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XX['Earthquake Magnitude'].max() - XX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XX[(XX['Earthquake Magnitude'] >= start_dist) & (XX['EarthquakeMagnitude'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Earthquake Magnitude'] >= start_dist) &(XX['Earthquake Magnitude'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PGA']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PGA Residual vs Mw')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "48\n",
    "num_intervals = int((XX['Earthquake Magnitude'].max() - XX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_inter', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XX[(XX['Earthquake Magnitude'] >= start_dist) & (XX['EarthquakeMagnitude'] < end_dist)]\n",
    "    interval_data = residue_inter[(XX['Earthquake Magnitude'] >= start_dist) &(XX['Earthquake Magnitude'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PSA 0.01s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_inter']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_inter\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.01s) vs Mw')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(conditions_inter[:,0],residue_inter['log PSA 0.01s'])\n",
    "# plt.xlabel('Mw')\n",
    "# plt.ylabel('Residue')\n",
    "# plt.title('Earthquake Magnitude vs PSA 0.01s Residue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(conditions_inter[:,0],residue_inter['log PSA 0.05s'])\n",
    "# plt.xlabel('Mw')\n",
    "# plt.ylabel('Residue')\n",
    "# plt.title('Earthquake Magnitude vs PSA 0.05s Residue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "intra['Mw/Rjb'] = np.array(intra['Earthquake Magnitude']) / np.array(intra['Joyner-Boore Dist. (km)'])\n",
    "intra['log Rjb'] = np.log10(intra['Joyner-Boore Dist. (km)'])\n",
    "49\n",
    "yyy = pd.DataFrame()\n",
    "yyy['log PGA'] = np.log10(intra['PGA-H RotDnn (g)'])\n",
    "yyy['log PGV'] = np.log10(intra['PGV-H RotDnn (cm/s)'])\n",
    "t = [0.01 , 0.02 , 0.03 , 0.04 , 0.05,0.06 ,0.07 , 0.08 ,0.09,0.1,0.2 , 0.3 , 0.\n",
    "4, 0.5 ,0.6, 0.7,0.8,0.9,1,2,3,4,5]\n",
    "for i in t:\n",
    "    yyy[f\"log PSA {i}s\"] = np.log10(intra[f\"T{i}s\"])\n",
    "XXX = intra[['Earthquake Magnitude', 'Joyner-Boore Dist. (km)', 'log Rjb','Mechanism Based on Rake Angle', 'Preferred VS30 (m/sec)']]\n",
    "# XXX = intra[['Earthquake Magnitude', 'log Rjb', 'Preferred VS30 (m/sec)']]\n",
    "# x_train2, x_test2, y_train2, y_test2 = sk.train_test_split(XXX, yyy,test_size = 0.15, random_state = 42)\n",
    "# x_test2, x_val2, y_test2, y_val2 = sk.train_test_split(x_test2, y_test2,test_size = 0.5, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions_intra = XXX[['Earthquake Magnitude', 'log Rjb', 'Preferred VS30 (m/sec)']]\n",
    "conditions_intra = conditions_intra.to_numpy()\n",
    "conditions_intra_pred = scaler_cond.transform(conditions_intra)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(conditions_intra_pred, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)\n",
    "intra_y_pred = np.mean(mean_output, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "residue_intra = yyy - intra_y_pred[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(conditions_intra[:,0],residue_intra['log PSA 0.01s'])\n",
    "# plt.xlabel('Mw')\n",
    "# plt.ylabel('Residue')\n",
    "# plt.title('Earthquake Magnitude vs PSA 0.01s Residue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XXX['Joyner-Boore Dist. (km)'].max() - XXX['Joyner-BooreDist. (km)'].min()) / 200) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_intra', 'Rjb (km)'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = i * 200\n",
    "    end_dist = start_dist + 200\n",
    "    intervals_X = XXX[(XXX['Joyner-Boore Dist. (km)'] >= start_dist) &(XXX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    interval_data = residue_intra[(XXX['Joyner-Boore Dist. (km)'] >= start_dist)& (XXX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PSA 0.01s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_intra']=residue_intervals\n",
    "    df2['Rjb (km)']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Rjb (km)\", y=\"residue_intra\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Rjb (km)\", y=\"residue_intra\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.01s) vs Rjb(km)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XXX['Joyner-Boore Dist. (km)'].max() - XXX['Joyner-BooreDist. (km)'].min()) / 200) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_intra', 'Rjb (km)'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = i * 200\n",
    "    end_dist = start_dist + 200\n",
    "    intervals_X = XXX[(XXX['Joyner-Boore Dist. (km)'] >= start_dist) &(XXX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    interval_data = residue_intra[(XXX['Joyner-Boore Dist. (km)'] >= start_dist)& (XXX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PSA 0.2s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_intra']=residue_intervals\n",
    "    df2['Rjb (km)']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Rjb (km)\", y=\"residue_intra\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Rjb (km)\", y=\"residue_intra\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.2s) vs Rjb(km)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XXX['Joyner-Boore Dist. (km)'].max() - XXX['Joyner-BooreDist. (km)'].min()) / 200) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_intra', 'Rjb (km)'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = i * 200\n",
    "    end_dist = start_dist + 200\n",
    "    intervals_X = XXX[(XXX['Joyner-Boore Dist. (km)'] >= start_dist) &(XXX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    interval_data = residue_intra[(XXX['Joyner-Boore Dist. (km)'] >= start_dist)& (XXX['Joyner-Boore Dist. (km)'] < end_dist)]\n",
    "    residue_intervals = interval_data['log PGA']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_intra']=residue_intervals\n",
    "    df2['Rjb (km)']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Rjb (km)\", y=\"residue_intra\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Rjb (km)\", y=\"residue_intra\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PGA Residual vs Rjb(km)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XXX['Earthquake Magnitude'].max() - XXX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_intra', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XXX[(XXX['Earthquake Magnitude'] >= start_dist) &(XXX['Earthquake Magnitude'] < end_dist)]\n",
    "    intraval_data = residue_intra[(XXX['Earthquake Magnitude'] >= start_dist) &(XXX['Earthquake Magnitude'] < end_dist)]\n",
    "    54\n",
    "    residue_intervals = intraval_data['log PSA 0.01s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_intra']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "    ax = sns.stripplot(x=\"Mw\", y=\"residue_intra\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_intra\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.01s) vs Mw')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "num_intervals = int((XXX['Earthquake Magnitude'].max() - XXX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_intra', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XXX[(XXX['Earthquake Magnitude'] >= start_dist) &(XXX['Earthquake Magnitude'] < end_dist)]\n",
    "    intraval_data = residue_intra[(XXX['Earthquake Magnitude'] >= start_dist) &(XXX['Earthquake Magnitude'] < end_dist)]\n",
    "    residue_intervals = intraval_data['log PSA 0.2s']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_intra']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Mw\", y=\"residue_intra\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_intra\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PSA Residual (T=0.2s) vs Mw')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as P\n",
    "56\n",
    "num_intervals = int((XXX['Earthquake Magnitude'].max() - XXX['EarthquakeMagnitude'].min())) + 1\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "df1 = pd.DataFrame(columns = ['residue_intra', 'Mw'])\n",
    "for i in range(num_intervals):\n",
    "    start_dist = (i+3) * 1\n",
    "    end_dist = start_dist + 1\n",
    "    intervals_X = XXX[(XXX['Earthquake Magnitude'] >= start_dist) &(XXX['Earthquake Magnitude'] < end_dist)]\n",
    "    intraval_data = residue_intra[(XXX['Earthquake Magnitude'] >= start_dist) &(XXX['Earthquake Magnitude'] < end_dist)]\n",
    "    residue_intervals = intraval_data['log PGA']\n",
    "    df2 = pd.DataFrame()\n",
    "    df2['residue_intra']=residue_intervals\n",
    "    df2['Mw']=(start_dist+end_dist)/2\n",
    "    df1 = pd.concat([df1,df2], ignore_index=True)\n",
    "ax = sns.stripplot(x=\"Mw\", y=\"residue_intra\", data=df1, ax= ax,marker=\"$\\circ$\", color=\".25\")\n",
    "ax = sns.boxplot(x=\"Mw\", y=\"residue_intra\", data=df1, ax=ax)\n",
    "ax.axhline(0, ls='--', color='r')\n",
    "plt.title('PGA Residual vs Mw')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.scatter(XXX['Joyner-Boore Dist. (km)'],residue_intra['log PSA 0.01s'])\n",
    "# plt.xlabel('Rjb (km)')\n",
    "# plt.ylabel('Residue')\n",
    "# plt.title('Rupture Distance vs PSA 0.01s Residue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = pd.DataFrame(columns = ['Mw', 'logRjb', 'Vs30'])\n",
    "X_plot.loc[0] = [3, math.log10(10), 760]\n",
    "X_plot.loc[1] = [4, math.log10(10), 760]\n",
    "X_plot.loc[2] = [5, math.log10(10), 760]\n",
    "X_plot = scaler_cond.transform(X_plot.to_numpy())\n",
    "# predicted_outputs = predict(X_plot, generator, device)\n",
    "# predicted_outputs = scaler.inverse_transform(predicted_outputs)\n",
    "# predicted_outputs = np.power(10, predicted_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.plot(PSA_tp, predicted_outputs[0][5:], linestyle='--', marker = 'd',label=\"Mw=3\")\n",
    "# plt.plot(PSA_tp, predicted_outputs[1][5:], linestyle='--', marker = 's',label=\"Mw=4\")\n",
    "# plt.plot(PSA_tp, predicted_outputs[2][5:], linestyle='--', marker = '^',label=\"Mw=5\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.title(\"PSA vs Time(s) for Single Prediction\")\n",
    "# plt.xlabel(\"Time Period(s)\")\n",
    "# plt.ylabel(\"PSA(g)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(X_plot, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)\n",
    "mean_array = np.mean(mean_output, axis=0)\n",
    "mean_array = np.power(10, mean_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PSA_tp, mean_array[0][5:], linestyle='--', marker = 'd', label=\"Mw=3\")\n",
    "plt.plot(PSA_tp, mean_array[1][5:], linestyle='--', marker = 's', label=\"Mw=4\")\n",
    "plt.plot(PSA_tp, mean_array[2][5:], linestyle='--', marker = '^', label=\"Mw=5\")\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"PSA vs Time Period(s)\")\n",
    "plt.xlabel(\"Time Period(s)\")\n",
    "plt.ylabel(\"PSA(g)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = pd.DataFrame(columns = ['Mw', 'logRjb', 'Vs30'])\n",
    "X_plot.loc[0] = [4, math.log10(10), 760]\n",
    "X_plot.loc[1] = [4, math.log10(50), 760]\n",
    "X_plot.loc[2] = [4, math.log10(100), 760]\n",
    "X_plot.loc[3] = [4, math.log10(150), 760]\n",
    "X_plot = scaler_cond.transform(X_plot.to_numpy())\n",
    "# predicted_outputs = predict(X_plot, generator, device)\n",
    "# predicted_outputs = scaler.inverse_transform(predicted_outputs)\n",
    "# predicted_outputs = np.power(10, predicted_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.plot(PSA_tp, predicted_outputs[0][5:], linestyle='--', marker = 'd',label=\"Rjb=10km\")\n",
    "# plt.plot(PSA_tp, predicted_outputs[1][5:], linestyle='--', marker = 's',label=\"Rjb=50km\")\n",
    "# plt.plot(PSA_tp, predicted_outputs[2][5:], linestyle='--', marker = '^',label=\"Rjb=100km\")\n",
    "# plt.grid(True, which=\"both\")\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.title(\"PSA vs Time(s) for Single Predictions\")\n",
    "# plt.xlabel(\"Time Period(s)\")\n",
    "# plt.ylabel(\"PSA(g)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(X_plot, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)\n",
    "mean_array = np.mean(mean_output, axis=0)\n",
    "mean_array = np.power(10, mean_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(PSA_tp, mean_array[0][5:], linestyle='--', marker = 'd',label=\"Rjb=10km\")\n",
    "plt.plot(PSA_tp, mean_array[1][5:], linestyle='--', marker = 's',label=\"Rjb=50km\")\n",
    "plt.plot(PSA_tp, mean_array[2][5:], linestyle='--', marker = '^',label=\"Rjb=100km\")\n",
    "plt.plot(PSA_tp, mean_array[3][5:], linestyle='--', marker = '*',label=\"Rjb=150km\")\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"PSA vs Time Period(s)\")\n",
    "plt.xlabel(\"Time Period(s)\")\n",
    "plt.ylabel(\"PSA(g)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = {0:'d', 1:'s', 2:'^', 3:'*', 4:'o', 5:'+'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = pd.DataFrame(columns = ['Mw', 'logRjb', 'Vs30'])\n",
    "X_plot.loc[0] = [4, math.log10(100), 540]\n",
    "X_plot.loc[1] = [4, math.log10(100), 760]\n",
    "X_plot.loc[2] = [4, math.log10(100), 1080]\n",
    "X_plot = scaler_cond.transform(X_plot.to_numpy())\n",
    "# predicted_outputs = predict(X_plot, generator, device)\n",
    "# predicted_outputs = scaler.inverse_transform(predicted_outputs)\n",
    "# predicted_outputs = np.power(10, predicted_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_output = []\n",
    "for i in range(1000):\n",
    "    output = predict(X_plot, generator, device)\n",
    "    output = scaler.inverse_transform(output)\n",
    "    mean_output.append(output)\n",
    "mean_array = np.mean(mean_output, axis=0)\n",
    "mean_array = np.power(10, mean_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(PSA_tp, mean_array[0][5:], linestyle='--', marker = 'd',label=\"Vs30=760km\")\n",
    "plt.plot(PSA_tp, mean_array[1][5:], linestyle='--', marker = 's',label=\"Vs30=1080km\")\n",
    "plt.plot(PSA_tp, mean_array[2][5:], linestyle='--', marker = '^',label=\"Vs30=1540km\")\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"PSA vs Time Period(s)\")\n",
    "plt.xlabel(\"Time Period(s)\")\n",
    "plt.ylabel(\"PSA(g)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_Rjb = []\n",
    "for i in range(200):\n",
    "    temp_Rjb.append((i+1)*5)\n",
    "X_plot = pd.DataFrame(columns = ['Mw', 'logRjb', 'Vs30'])\n",
    "for i in range(200):\n",
    "    X_plot.loc[i] = [5, np.log10((i+1)*5), 2000]\n",
    "X_plot = scaler_cond.transform(X_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_predictions = []\n",
    "for i in range(1000):\n",
    "    predictions = predict(X_plot, generator, device)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    mean_predictions.append(predictions)\n",
    "\n",
    "mean_array = np.mean(mean_predictions, axis=0)\n",
    "mean_array = np.power(10, mean_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multi_predictions = []\n",
    "pred_value = []\n",
    "for i in range(200):\n",
    "    multi_predictions.append([])\n",
    "    pred_value.append([])\n",
    "for i in range(1000):\n",
    "    predictions = predict(X_plot, generator, device)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    mean_predictions.append(predictions)\n",
    "for j in range(200):\n",
    "    multi_predictions[j].append(predictions[j])\n",
    "for i in range(200):\n",
    "    pred_value[i] = np.array(multi_predictions[i]).mean(axis=0)\n",
    "    # pred_value[i] = np.power(10, pred_value[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_plot = predict(X_plot, generator, device)\n",
    "y_plot = scaler.inverse_transform(y_plot)\n",
    "y_plot_new = []\n",
    "for i in range(200):\n",
    "    y_plot_new.append(y_plot[i][2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_plot = []\n",
    "for i in range(200):\n",
    "    temp_plot.append(pred_value[i][9])\n",
    "plt.plot(temp_Rjb, temp_plot)\n",
    "plt.title(\"PSA (T=0.1) vs Rjb(km)\")\n",
    "plt.ylabel(\"PSA (g)\")\n",
    "plt.xlabel(\"Rjb(km)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_plot = pd.DataFrame(columns = ['Mw', 'logRjb', 'Vs30'])\n",
    "temp_Mw = []\n",
    "for i in range(20,60):\n",
    "    temp_Mw.append((i+1)*0.1)\n",
    "j=0\n",
    "for i in range(20,60):\n",
    "    X_plot.loc[j] = [(i+1)*0.1, np.log10(100), 760]\n",
    "    j+=1\n",
    "X_plot = scaler_cond.transform(X_plot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_predictions = []\n",
    "for i in range(1000):\n",
    "    predictions = predict(X_plot, generator, device)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    mean_predictions.append(predictions)\n",
    "mean_array = np.mean(mean_predictions, axis=0)\n",
    "mean_array = np.power(10, mean_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multi_predictions = []\n",
    "pred_value = []\n",
    "for i in range(40):\n",
    "    multi_predictions.append([])\n",
    "    pred_value.append([])\n",
    "for i in range(40):\n",
    "    predictions = predict(X_plot, generator, device)\n",
    "    predictions = scaler.inverse_transform(predictions)\n",
    "    mean_predictions.append(predictions)\n",
    "    for j in range(40):\n",
    "        multi_predictions[j].append(predictions[j])\n",
    "for i in range(40):\n",
    "    pred_value[i] = np.array(multi_predictions[i]).mean(axis=0)\n",
    "    # pred_value[i] = np.power(10, pred_value[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_plot = predict(X_plot, generator, device)\n",
    "y_plot = scaler.inverse_transform(y_plot)\n",
    "y_plot_new = []\n",
    "for i in range(40):\n",
    "    y_plot_new.append(y_plot[i][2:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_plot = []\n",
    "for i in range(40):\n",
    "    temp_plot.append(pred_value[i][9])\n",
    "plt.plot(temp_Mw, temp_plot)\n",
    "plt.title(\"PSA (g) vs Mw\")\n",
    "plt.ylabel(\"PSA (T=0.1s)\")\n",
    "plt.xlabel(\"Mw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "his = pd.read_csv('/content/drive/MyDrive/Seismic/results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "his.columns = ['i', 'best_r2', 'curr_r2', 'd_loss', 'g_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "his\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r2_his = his['curr_r2']\n",
    "d_loss_his = his['d_loss']\n",
    "g_loss_his = his['g_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_loss_mini = []\n",
    "g_loss_idx = []\n",
    "for i in range(len(g_loss_his)):\n",
    "    if(i%1000==0):\n",
    "        g_loss_mini.append(g_loss_his.iloc[i])\n",
    "        g_loss_idx.append(i)\n",
    "plt.plot(g_loss_idx, g_loss_mini)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Generator Loss')\n",
    "plt.title('Generator Loss vs Number of Epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_loss_mini = []\n",
    "d_loss_idx = []\n",
    "for i in range(len(d_loss_his)):\n",
    "    if(i%1000==0):\n",
    "        d_loss_mini.append(d_loss_his.iloc[i])\n",
    "        d_loss_idx.append(i)\n",
    "plt.plot(d_loss_idx, d_loss_mini)\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Discriminator Loss')\n",
    "plt.title('Discriminator Loss vs Number of Epochs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
